# test

# 说明
现在想把这个工作改投到期刊上，需要做一些改进和扩容的工作。改进和扩容的工作可以分成以下三个方向进行：
1）讨论加residual block的意义和重要性。

2）讨论采用之前那个训练方法的重要性。

3）讨论采用不同的reference的重要行。

4）讨论spatical-wise information 和 channel-wise information 结合的更优方法。

5）讨论TRA和SRA更优的结合方式。

6）讨论降低运算量的方法。

# exp1

虽然，当前的试验结果是最优的。但是，当去掉了residual block Rank1性能差不多下滑了1%。不知道是模型的波动还是什么其他的问题。
但是，在之前的实验中，证明了不用residual block 也是能达到比较好的性能的。可以对比一下，这两者的差别。


# 
